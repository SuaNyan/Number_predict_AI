{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b95bd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/takasatoyuuna/.venv/dm/lib/python3.9/site-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9683571428571428\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# MNISTデータセットをダウンロード\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True, as_frame=False)\n",
    "\n",
    "# 特徴量とラベルを取得\n",
    "X = mnist.data\n",
    "y = mnist.target\n",
    "\n",
    "# データを訓練用とテスト用に分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# モデルの構築と訓練\n",
    "model = MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# テストデータセットでの予測\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 正答率の計算\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0eceefb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train.astype(int)\n",
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ef8642e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# 手書き画像の読み込みと前処理\n",
    "i = 0\n",
    "while i <= 9:\n",
    "    image = Image.open('digits_' + str(i) + '.png').convert('L')  # 手書き画像のパスを指定して読み込む\n",
    "    image = image.resize((28, 28))  # 28x28にリサイズ\n",
    "    image = np.array(image)  # NumPy配列に変換\n",
    "    image = image.reshape(1, -1)  # 1次元の特徴量ベクトルに変換\n",
    "    #image = image / 255.0  # スケーリング (0から1の範囲に正規化)\n",
    "    image = 255.0 - image\n",
    "\n",
    "    # ラベルの作成\n",
    "    label = np.array([i])\n",
    "\n",
    "    # データを追加\n",
    "    X_train = np.append(X_train,image,axis=0)\n",
    "    y_train = np.append(y_train,label)\n",
    "\n",
    "    i += 1\n",
    "\n",
    "# 新しい学習データでモデルを再訓練\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# テストデータセットでの予測\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 正答率の計算\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Updated Accuracy:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b52e3c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ccd0dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    4.   4.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  68. 160.\n",
      "  210. 210. 164.  67.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  17. 158. 254. 255.\n",
      "  255. 255. 255. 251.  90.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.  18. 192. 255. 255. 255.\n",
      "  217. 216. 253. 255. 195.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   2. 169. 255. 255. 224.  84.\n",
      "   10.  15. 220. 255. 199.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.  88. 255. 255. 221.  38.   0.\n",
      "    0.   0. 203. 255. 220.  11.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   5. 203. 255. 249.  67.   0.   0.\n",
      "    0.  69. 246. 255. 215.  10.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.  49. 252. 255. 177.   0.   0.   0.\n",
      "   59. 229. 255. 255. 135.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.  89. 255. 255.  95.   0.  15. 119.\n",
      "  242. 255. 255. 255.  69.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.  90. 255. 255. 143. 122. 218. 255.\n",
      "  255. 255. 255. 226.  15.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.  42. 250. 255. 255. 255. 255. 255.\n",
      "  253. 255. 255. 160.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0. 126. 252. 255. 255. 235. 146.\n",
      "  170. 255. 255.  82.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.  57. 102.  84.  28.   0.\n",
      "  203. 255. 234.  20.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  50.\n",
      "  251. 255. 172.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 130.\n",
      "  255. 255.  91.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   7. 211.\n",
      "  255. 236.  24.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  59. 253.\n",
      "  255. 166.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 141. 255.\n",
      "  255.  81.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  10. 219. 255.\n",
      "  229.  17.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  71. 254. 255.\n",
      "  157.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 161. 255. 255.\n",
      "   70.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 161. 255. 209.\n",
      "    8.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  24. 104.  41.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b6ebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 手書き数字の予測\n",
    "i = 0\n",
    "while i <= 9:\n",
    "    image = Image.open('digits_' + str(i) + '.png').convert('L')  # 手書き画像のパスを指定して読み込む\n",
    "    image = image.resize((28, 28))  # 28x28にリサイズ\n",
    "    image = np.array(image)  # NumPy配列に変換\n",
    "    image = image.reshape(1, -1)  # 1次元の特徴量ベクトルに変換\n",
    "    #image = image / 255.0  # スケーリング (0から1の範囲に正規化)\n",
    "    image = 255.0 - image\n",
    "\n",
    "    # モデルによる予測\n",
    "    prediction = model.predict(image)\n",
    "\n",
    "    # 結果の表示\n",
    "    plt.imshow(image.reshape(28, 28), cmap='gray')\n",
    "    plt.title(\"Predicted Label: \" + str(prediction[0]))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    i += 1\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
